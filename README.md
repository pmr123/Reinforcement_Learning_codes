# Practical_Reinforcement_Learning_codes

All codes are in python 3 and employ gym to produce environment

## List of codes :-
- [crossentropy_method](https://github.com/pmr123/Practical_Reinforcement_Learning_assignment_codes/blob/main/crossentropy_method.ipynb) =  Taxi-V3 problem using crossentropy method
- [practice_vi](https://github.com/pmr123/Practical_Reinforcement_Learning_assignment_codes/blob/main/practice_vi.ipynb) = value iteration process using demo MDP and frozen lake problem
- [qlearning](https://github.com/pmr123/Practical_Reinforcement_Learning_assignment_codes/blob/main/qlearning.ipynb) = Taxi-v3 and CartPole-v0 problems using Q Learning method. Cartpole solution utilizes binarized state spaces
- [sarsa](https://github.com/pmr123/Practical_Reinforcement_Learning_assignment_codes/blob/main/sarsa.ipynb) = Gridworld Cliff problem using Q Learning and Expected SARSA. Difference in mean reward and learned policy is shown
- [experience_replay](https://github.com/pmr123/Practical_Reinforcement_Learning_assignment_codes/blob/main/experience_replay.ipynb) = Taxi-V3 problem using Q Learning and Q Learning with experiance replay. Difference in performance in shown
- [practice_approx_qlearning](https://github.com/pmr123/Practical_Reinforcement_Learning_assignment_codes/blob/main/practice_approx_qlearning.ipynb) = CartPole-v0 problem using Approximate(Deep) Q Learning
